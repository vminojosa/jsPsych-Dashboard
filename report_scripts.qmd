```{python}
#| echo: false

# MODULES

import requests
import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

# API REQUEST

def fetch_api(endpoint):
  url = f"https://api.github.com/repos/jspsych/jsPsych/{endpoint}"
  token = os.environ['API_AUTH']
  headers = {'Authorization': f'token {token}'}
  final_data=[]
  while url:
   response = requests.get(url, headers=headers)
   data = response.json()
   for item in data:
     final_data.append(item)
   if 'next' in response.links:
     url = response.links['next']['url']
   else:
     break
  return final_data

# BUILD BASE DATAFRAMES

def create_dataframe():
  entries = []
  for item in cache:
    entry = {
    'issue_number': item['number'],
    'user': item['user']['login'],
    'created_at': pd.to_datetime(item['created_at']),
    'closed_at': pd.to_datetime(item['closed_at']) if item['closed_at'] else None,
    'state': item['state'],
    'title': item['title'],
    'ent_type': 'pull' if 'pull_request' in item else 'issue',
    'pull_request': item['pull_request'] if 'pull_request' in item else None
    }
    entries.append(entry)
  df = pd.DataFrame(entries)
  df['year'] = df['created_at'].dt.year
  df['quarter'] = df['created_at'].dt.quarter

  return df

def select_ent(ent_type):
  df = create_dataframe()
  if ent_type == 'pulls':
    return df[df['ent_type'].isin(['pull'])]
  else:
    return df[df['ent_type'].isin(['issue'])].drop('pull_request', axis=1)

def create_comm_dataframe():
    comments = []
    for comment in comm_cache:
        comment_entry = {
            'issue_number': int(comment['issue_url'].split('/')[-1]),
            'user': comment['user']['login'],
            'created_at': pd.to_datetime(comment['created_at']),
            'body': comment['body']
        }
        comments.append(comment_entry)

    return pd.DataFrame(comments)

def analyze_interaction_times(df, comments_df):
  if comments_df.empty:
    print("Warning: Comments dataframe is empty")
    df['comment_count'] = 0
    df['avg_interaction_time'] = None
    return df

  comments_by_issue = comments_df.groupby('issue_number').agg({
    'created_at': list,
    'issue_number': 'count'
  }).rename(columns={'issue_number': 'comment_count'})

  df = df.merge(comments_by_issue, left_on='issue_number', right_index=True, how='left')
  df['comment_count'] = df['comment_count'].fillna(0)

  if 'created_at_x' not in df.columns and 'created_at_y' not in df.columns:
    df = df.rename(columns={'created_at': 'created_at_x'})
    if 'created_at' in df.columns:
      df['created_at_y'] = df['created_at']

  def calculate_interaction_time(row):
    if pd.isna(row)['created_at_y']:
      return None
    dates = [row['created_at_x']] + row['created_at_y']
    if row['closed_at'] is not None:
      dates.append(row['closed_at'])
    dates = [d for d in dates if pd.notna(d)] # --> is this step necessary?
    dates = sorted(dates)
    if len(dates) > 1:
      time_diff = np.diff([d.timestamp() for d in dates])
      time_diff = time_diff / (60 * 60 * 24) # convert to days
      return np.mean(time_diff) if len(time_diff) > 0 else None
    return None
  
  def calculate_merge_time(row):
    if pd.isna(row['pull_request']['merged_at']):
      return None
    created_at = row['created_at_x'].timestamp()
    pr = row['pull_request']
    merged_at = pd.to_datetime(pr['merged_at']).timestamp()
    return (merged_at - created_at) / (60 * 60 * 24) # convert to days
  
  df['avg_interaction_time'] = df.apply(calculate_interaction_time, axis=1)
  if 'pull_request' in df.columns:
    df['merge_time'] = df.apply(calculate_merge_time, axis=1)

  return df

def quarterly_metrics(df):
  if 'merge_time' in df.columns:
    return df.groupby(['year', 'quarter']).agg({
      'issue_number': 'count',
      'avg_interaction_time': 'mean',
      'comment_count': ['mean', 'sum'],
      'merge_time': 'mean'
    }).round(2)
  return df.groupby(['year', 'quarter']).agg({
  'issue_number': 'count',
  'avg_interaction_time': 'mean',
  'comment_count': ['mean', 'sum']
  }).round(2)

def generate_report():
  issues_df = select_ent('issues')
  pulls_df = select_ent('pulls')
  comments_df = create_comm_dataframe()

  issues_analysis = analyze_interaction_times(issues_df, comments_df)
  pulls_analysis = analyze_interaction_times(pulls_df, comments_df)

  issues_quarterly = quarterly_metrics(issues_analysis)
  pulls_quarterly = quarterly_metrics(pulls_analysis)

  return issues_analysis, pulls_analysis, issues_quarterly, pulls_quarterly

# SORTED FRAMES

def open_awhile(frame):
  df = frame.loc[frame['state'] == 'open']
  return df.loc[df['year'] < 2024]

# VISUALS

def plot_quarterly_metrics(metrics, target_metric):
  plt.figure(figsize=(10, 6))
  for year in metrics.index.get_level_values('year').unique():
    year_data = metrics.loc[year]
    plt.plot(year_data.index, year_data[target_metric],
            marker='o', label=f'Year {year}')

  plt.xlabel('Quarter')
  plt.ylabel(target_metric)
  plt.title(f'Quarterly {target_metric} Over Time')
  plt.legend()
  plt.grid(True)
  plt.show()

def plot_history(metrics, target_metric):
  plt.figure(figsize=(10, 6))
  quarters = [f'{year} Q{quarter}' for year, quarter in metrics.index]
  plt.plot(quarters, metrics[target_metric],
    marker='o')

  plt.xlabel('Quarter')
  plt.xticks(rotation=90)
  plt.ylabel(target_metric)
  plt.title(f'Quarterly {target_metric} Over Time')
  plt.legend()
  plt.grid(True)
  plt.show()

def calculate_d_times(metrics):
    if ('merge_time', 'mean') in metrics.columns:
        df = my_prs_analysis
    else:
        df = my_issues_analysis

    open_df = df.loc[df['year'] == 2025].loc[df['quarter'] == 1].loc[df['state'] == 'open']
    open_df = open_df.drop(columns = [
        'user', 
        'closed_at', 
        'state', 
        'title', 
        'ent_type',
        'year', 
        'quarter', 
        'comment_count', 
        'merge_time'])

    now = datetime.datetime.now().timestamp()
    d_times = [(now-date.timestamp())/(60*60*24) for date in open_df['created_at_x']]
    times_df = open_df.assign(d_time = d_times)
    return times_df

def calculate_d_metrics(metrics, target_metric):
    count = metrics.loc[2025].loc[1][('issue_number', 'count')]
    target = metrics.loc[2025].loc[1][target_metric]
    print(f'the current time is {target} days to merge')
    times_df = calculate_d_times(metrics)
    print(f'there are {len(times_df)} open pull requests')
    d_means = []
    for t in times_df['d_time']:
        print(f'as of now, this pr would have taken {t} days to merge')
        print(f'the mean would change by {(t - target) / (count + 1)} days')
        d_means.append((t-target) / (count + 1))
    times_df = times_df.assign(d_mean = d_means)
    times_df = times_df.sort_values('d_mean')
    url = times_df.iloc[-1]['pull_request']['html_url']
    d_metric = sum(d_means) / len(d_means)
    return [d_metric, url]

def plot_performance_comparison(metrics, target_metric):
    plt.figure(figsize=(4, 6))

    year = metrics.index.get_level_values('year')[-1]

    quarter = metrics.index.get_level_values('quarter')[-1]
    prev_year = metrics.loc[year-1].loc[quarter][target_metric]
    if quarter == 1:
        prev_quarter = metrics.loc[year-1].loc[4][target_metric]
    else:
        prev_quarter = metrics.loc[year].loc[quarter-1][target_metric]

    x = 'Current Quarter'
    y = metrics.loc[year].loc[quarter][target_metric]

    delta_array = calculate_d_metrics(metrics, target_metric)
    delta = delta_array[0]
    url = delta_array[1]
    print(f'the pr that would impact mean merge time the most is: {url}')

    rank = sorted([prev_year, prev_quarter, y, y+delta])
    if (y+delta) == rank[0]:
        d_color = 'green'
    if (y+delta) == rank[-1]:
        d_color = 'red'
    else:
        d_color = 'yellow'

    plt.bar(x, y)
    plt.axhline(y=prev_year, color="black", linestyle=":", label='This Quarter Last Year')
    plt.axhline(y=prev_quarter, color="black", linestyle="--", label='Previous Quarter')
    plt.axhline(y=y+delta, color=f"{d_color}", linestyle="-", label='Merging All Open PRs in Quarter')
    plt.legend()
    plt.ylabel(target_metric)
    plt.title(f'Performance Comparison for {target_metric}')
    plt.show()

cache = fetch_api(f"issues?state=all&per_page=100")
comm_cache = fetch_api(f"issues/comments?per_page=100")

my_issues_analysis, my_prs_analysis, my_issues_quarterly, my_prs_quarterly = generate_report()
```
